{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5510 4750\n",
      "129\n",
      "148\n",
      "984\n",
      "3485\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch import tensor \n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\"\"\"k fold 대신 stratified k fold\"\"\"\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import itertools\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# psychosocial + rsfMRI + strurctural MRI + diffusion MRI\n",
    "\n",
    "\n",
    "dataset_name = 'rsf_s_dMRI'\n",
    "train_out = Path(os.getcwd()+'/Data/si_ppc_'+dataset_name+'_train.csv')\n",
    "test_out =Path(os.getcwd()+'/Data/si_ppc_'+dataset_name+'_test.csv')\n",
    "\n",
    "\n",
    "train_data= pd.read_csv(train_out)\n",
    "test_data= pd.read_csv(test_out)\n",
    "\n",
    "\n",
    "target ='Suicidalideation'\n",
    "unused_feat = ['abcd_site','kfold']\n",
    "\n",
    "# mri feature가 시작하는 column의 index 구하기\n",
    "# np.where의 결과값이 array에 들어가기 때문에 방금 계산해 넣어놓은 [0]번째 값을 가져온다.\n",
    "start_psycho_index = np.where(test_data.columns.values == \"race.ethnicity_1\")[0][0]\n",
    "start_rsfmri_index = np.where(test_data.columns.values == \"rsfmri_var_cort.destrieux_g.and.s.frontomargin.lh\")[0][0]\n",
    "# start_rsfmri_index = np.where(test_data.columns.values == \"rsfmri_var_cort.destrieux_g.and.s.frontomargin.lh\")[0][0]\n",
    "start_structmri_index = np.where(test_data.columns.values == \"lh_bankssts_area._.1\")[0][0]\n",
    "start_diffmri_index = np.where(test_data.columns.values == \"con_L.BSTS_L.CACG_count\")[0][0]\n",
    "\n",
    "psychosocial = list(test_data.columns[start_psycho_index:start_rsfmri_index])\n",
    "rsf_mri = list(test_data.columns[start_rsfmri_index:start_structmri_index])\n",
    "structural_mri = list(test_data.columns[start_structmri_index:start_diffmri_index])\n",
    "diffusion_mri = list(test_data.columns[start_diffmri_index:])\n",
    "\n",
    "\n",
    "\n",
    "Num_FOLDS  = 5\n",
    "# the number of feature that you want to show \n",
    "Num_feat = 20\n",
    "\n",
    "\n",
    "print(len(train_data), len(train_data.columns))\n",
    "print(len(psychosocial))\n",
    "print(len(rsf_mri))\n",
    "print(len(structural_mri))\n",
    "print(len(diffusion_mri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine object featrues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For getting feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(Num_feat, clf_res, test_data_processed, features):\n",
    "    importance_res = []\n",
    "    for i in clf_res:\n",
    "        importance_clf =i.feature_importances_\n",
    "        importance_res.append(importance_clf)\n",
    "    \n",
    "    importance=[importance_res[0][i]/5+importance_res[1][i]/5+ importance_res[2][i]/5+ importance_res[3][i]/5+ importance_res[4][i]/5 for i in range(len(importance_res[1]))]\n",
    "    \n",
    "    #print(importance)\n",
    "    #plt.plot(importance)\n",
    "    #plt.show()\n",
    "\n",
    "    #importance_sort = importance.sort(reverse=True)\n",
    "    \n",
    "    #labels_importance=importance.argsort()[::-1]\n",
    "\n",
    "    #feat_name_sort=test_data_processed[features].columns[labels_importance]\n",
    "    feat_name_sort = test_data_processed[features].columns\n",
    "    important_features = pd.DataFrame([importance],columns = feat_name_sort, index=['Importance']) \n",
    "    important_features =important_features.transpose().sort_values(by=['Importance'], ascending=False)\n",
    "    important_features = important_features.head(50)\n",
    "    \"\"\"\n",
    "    for i in range (len(test_data_processed[features].columns)):\n",
    "        feature = pd.DataFrame([[feat_name_sort[i],importance_sort[i]]], columns = ['feature name', 'ratio'])\n",
    "        important_features=pd.concat([important_features,feature])\n",
    "    \"\"\"\n",
    "    return important_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function for preprocessing for Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing (train_data, test_data, NUM_FOLDS):\n",
    "    test_data_processed= test_data.fillna(0).reset_index(drop=True)\n",
    "    train_data_processed = train_data.fillna(0).reset_index(drop=True)\n",
    "    \n",
    "    # 추가? 값 변경?\n",
    "    test_data_processed[\"kfold\"] = -1\n",
    "    train_data_processed[\"kfold\"] = -1\n",
    "\n",
    "    # frac: 전체 row 중 몇 %를 반환할 지 결정 -> frac=1을 설정해서 모든 데이터를 반환\n",
    "    # random_state: 추후 이것과 동일한 샘플링을 재현하기 위함\n",
    "    # sample: 데이터에서 임의의 샘플 선정 -> frac=1이면 전체 data의 순서만 임의로 바뀜\n",
    "    train_data_processed = train_data_processed.sample(frac=1,random_state=2020).reset_index(drop=True)\n",
    "    \n",
    "    \"\"\"stratified로 수정\"\"\"\n",
    "    # kf = KFold(n_splits=NUM_FOLDS) \n",
    "    kf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state =0)\n",
    "    \n",
    "    # enumerate: 각 split된 data set 순서대로 index를 함께 반환\n",
    "        # ex. fold 0 일 때, 80%는 trn_, 20%는 val_\n",
    "    for fold, (trn_, val_) in enumerate(kf.split(X=train_data_processed, y=train_data_processed[target])):\n",
    "        #print(len(trn_), len(val_)) -> 출력: 4408, 1102\n",
    "        # 'kfold' 칼럼은 cross validation할 때 fold 순서를 지정해놓은 것. \n",
    "        train_data_processed.loc[val_, 'kfold'] = fold\n",
    "    \n",
    "    print(\"done preprocessing\")\n",
    "    return train_data_processed, test_data_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented\n",
    "import torch\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def find_bestpar(fold, train_data_processed, test_data_processed, features):\n",
    "    \n",
    "    \"\"\"test data 생성\"\"\"\n",
    "    X_test = test_data_processed[features].values\n",
    "    Y_test = test_data_processed[target].values\n",
    "    \n",
    "    # Store maximum auc\n",
    "    max_auc= 0\n",
    "    # Store maximum hypterparameter set\n",
    "    max_hy = []\n",
    "    \"\"\"\n",
    "    # define hyperparameter space : learning rate, \n",
    "    n_ = [4,8,16]                              # \n",
    "    lr_ = [2e-2, 1e-2, 5e-3, 2e-3, 1e-3, 1e-4] # learning rate\n",
    "    w_ = [0.01, 0.001, 0.0001]                 # weight decay\n",
    "    g_ = [0.95, 0.99, 0.9]                     # scheduler params - gamma\n",
    "    ss_ = [10, 20, 30]                         # scheduler params - step_size\n",
    "    \n",
    "    # Orginal hyperparameter space \n",
    "    \"\"\"\n",
    "    # define hyperparameter space (quick version)\n",
    "    n_ = [4,16]\n",
    "    lr_ = [2e-2,1e-3]\n",
    "    w_ = [0.01,0.001]\n",
    "    g_ = [0.95,0.99]\n",
    "    ss_ = [10,30]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    all_ = [n_, lr_, w_, g_, ss_]\n",
    "    h_space = [s for s in itertools.product(*all_)]\n",
    "    \n",
    "    for hy in tqdm(h_space):\n",
    "        \"\"\"===================Cross Validation===================\"\"\"\n",
    "        \n",
    "        \"\"\"validation & test 결과\"\"\"\n",
    "        valid_res = []\n",
    "        test_auc_res = []\n",
    "        test_acc_res = []\n",
    "     \n",
    "        for i in range(fold):\n",
    "            #print(\"fold \", i)\n",
    "            # 5개의 fold 사용했으므로 변수 fold 값은 차례대로 0,1,2,3,4 중 하나\n",
    "            clf = TabNetClassifier(n_a = hy[0],\n",
    "                                n_d = hy[0],\n",
    "                                optimizer_params = dict(lr=hy[1], weight_decay=hy[2]),\n",
    "                                scheduler_params={\"step_size\":hy[4], \"gamma\":hy[3]},\n",
    "                                scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                                verbose=0)\n",
    "            \n",
    "            df_train = train_data_processed[train_data_processed.kfold != i]  # 5개 중 4개 train에 할당\n",
    "            df_valid = train_data_processed[train_data_processed.kfold == i]  # 5개 중 1개 validation에 할당\n",
    "            \n",
    "            X_train = df_train[features].values\n",
    "            Y_train = df_train[target].values\n",
    "            \n",
    "            X_valid = df_valid[features].values\n",
    "            Y_valid = df_valid[target].values\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            clf.fit(X_train, Y_train, eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
    "                    eval_name=['train', 'valid'], eval_metric=['auc'],\n",
    "                    max_epochs=200 , patience=20)\n",
    "       \n",
    "            preds_acc = clf.predict(X_test)\n",
    "            preds_prob = clf.predict_proba(X_test)\n",
    "            test_auc = roc_auc_score(y_score=preds_prob[:,1], y_true=Y_test)\n",
    "            test_acc = accuracy_score(preds_acc, Y_test)\n",
    "            \n",
    "            valid_res.append(clf.best_cost)\n",
    "            test_auc_res.append(test_auc)\n",
    "            test_acc_res.append(test_acc)\n",
    "            print('[%3d/%4d] '%(i+1, fold),'Valid score: %2f'% clf.best_cost, 'Test AUC: %.3f%%'%test_auc, 'Test ACC: %.3f%%'%test_acc)\n",
    "    \n",
    "        #print(valid_res)\n",
    "        #print(test_auc_res)\n",
    "        #print(test_acc_res)\n",
    "        \"\"\"valid와 test의 평균, 표준편차 출력\"\"\"\n",
    "        print(\"=====parameter별 valid, test score=====\")\n",
    "        print(\"Validation 평균: %3f\"%np.mean(valid_res), \"Test AUC 평균: %3f\"%np.mean(test_auc_res), \"Test ACC 평균: %3f\"%np.mean(test_acc_res))\n",
    "\n",
    "        if np.mean(test_auc_res)>max_auc:\n",
    "            print(\"Find new maximum AUC!!\")\n",
    "            max_hy = hy\n",
    "            max_auc = np.mean(test_auc_res)\n",
    "    \n",
    "    return max_hy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Train with best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestpar_tuning(fold, train_data_processed, test_data_processed, max_hy, features):\n",
    "    hy = max_hy\n",
    "    print(\"Max hy:\" ,hy)\n",
    "    X_test = test_data_processed[features].values\n",
    "    Y_test = test_data_processed[target].values\n",
    "    \"\"\"validation & test 결과\"\"\"\n",
    "    valid_res = []\n",
    "    test_auc_res = []\n",
    "    test_acc_res = []\n",
    "    clf_res = []\n",
    "    preds_prob_res = []\n",
    "    \n",
    "    \"\"\"해당 버전에 추가된 코드\"\"\"    \n",
    "    y_valid_true = []\n",
    "    y_valid_pred = []\n",
    "    y_test_pred = []\n",
    "    \n",
    "    y_valid_subject = []\n",
    "    y_test_subject = []\n",
    "    \n",
    "    \n",
    "    for i in range(fold):\n",
    "        clf = TabNetClassifier(n_a = hy[0],n_d = hy[0],\n",
    "                           optimizer_params = dict(lr=hy[1], weight_decay=hy[2]),\n",
    "                           scheduler_params={\"step_size\":hy[4], \"gamma\":hy[3]},\n",
    "                           scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                           verbose=0)\n",
    "        \n",
    "        # 5개의 fold 사용했으므로 변수 fold 값은 차례대로 0,1,2,3,4 중 하나\n",
    "        df_train = train_data_processed[train_data_processed.kfold != i]  # 5개 중 4개 train에 할당\n",
    "        df_valid = train_data_processed[train_data_processed.kfold == i]  # 5개 중 1개 validation에 할당\n",
    "            \n",
    "        X_train = df_train[features].values\n",
    "        Y_train = df_train[target].values\n",
    "            \n",
    "        X_valid = df_valid[features].values\n",
    "        Y_valid = df_valid[target].values\n",
    "        \n",
    "        #print(X_valid)\n",
    "        # 학습 전 subject key 가져옴\n",
    "        y_valid_subject.append(df_valid['subjectkey'].values)\n",
    "        y_test_subject.append(test_data_processed['subjectkey'].values)  \n",
    "        \"\"\"해당 버전 추가 코드\"\"\"\n",
    "        y_valid_true.append(Y_valid)        \n",
    "        \n",
    "        # 학습\n",
    "        clf.fit(X_train, Y_train, eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n",
    "                        eval_name=['train', 'valid'], eval_metric=['auc'],\n",
    "                        max_epochs=200 , patience=20)\n",
    "        \n",
    "        # 결과들\n",
    "        \"\"\"fold별 validation & test data에 대한 target 예측 배열\"\"\"\n",
    "        \"\"\"해당 버전 추가 코드\"\"\"\n",
    "        preds_prob_val= clf.predict_proba(X_valid)[:,1]\n",
    "        y_valid_pred.append(preds_prob_val)\n",
    "        # y_valid_pred.append(clf.predict(X_valid))\n",
    "        y_test_pred.append(clf.predict(X_test))\n",
    "\n",
    "\n",
    "        preds_acc = clf.predict(X_test)\n",
    "        preds_prob = clf.predict_proba(X_test)\n",
    "        test_auc = roc_auc_score(y_score=preds_prob[:,1], y_true=Y_test)\n",
    "        test_acc = accuracy_score(preds_acc, Y_test)\n",
    "\n",
    "                    \n",
    "        valid_res.append(clf.best_cost)\n",
    "        test_auc_res.append(test_auc)\n",
    "        test_acc_res.append(test_acc)\n",
    "        print('[%3d/%4d] '%(i+1, fold),'Valid score: %2f'% clf.best_cost, 'Test AUC: %.3f'%test_auc, 'Test ACC: %.3f'%test_acc)\n",
    "        preds_prob_res.append(preds_prob)\n",
    "        clf_res.append(clf)\n",
    "    \n",
    "    \"\"\"valid와 test의 평균, 표준편차 출력\"\"\"\n",
    "    print(\"Validation 평균: %3f\"%np.mean(valid_res), \"Test AUC 평균: %3f \"%np.mean(test_auc_res), \"Test ACC 평균: %3f\"%np.mean(test_acc_res))\n",
    "    \n",
    "    preds_prob=[preds_prob_res[0][i]/5+preds_prob_res[1][i]/5+ preds_prob_res[2][i]/5+ preds_prob_res[3][i]/5+ preds_prob_res[4][i]/5 for i in range(len(preds_prob_res[1]))]\n",
    "    preds_prob = np.array(preds_prob)\n",
    "    valid_result = np.mean(valid_res)\n",
    "    test_auc = np.mean(test_auc_res)\n",
    "    test_acc = np.mean(test_acc_res) \n",
    "    \n",
    "    #return test_auc,test_acc ,valid_result, clf_res, preds_prob, X_test, Y_test, y_valid_pred, y_test_pred, y_valid_subject, y_test_subject\n",
    "    \"\"\"수정 필요\"\"\"\n",
    "    return test_auc,test_acc ,valid_result, clf_res, preds_prob, X_test, Y_test, y_valid_pred, y_test_pred, y_valid_subject, y_test_subject, y_valid_true\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run function, Split data and and cross validation. This needs to be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_data_processed, test_data_processed, fold, Num_feat, features):\n",
    "    name_test = test_data_processed['subjectkey'].values\n",
    "    print(\"-------------------------------Training Begining-------------------------------\")\n",
    "    n_ = [4,8,16]\n",
    "    lr_ = [2e-2, 1e-2, 5e-3, 2e-3, 1e-3, 1e-4]\n",
    "    w_ = [0.01, 0.001, 0.0001]\n",
    "    g_ = [0.95, 0.99, 0.9]\n",
    "    ss_ = [10, 20, 30]\n",
    "    all_ = [n_, lr_, w_, g_, ss_]\n",
    "    h_space = [s for s in itertools.product(*all_)]\n",
    "    \n",
    "    # Start training\n",
    "    max_hy = find_bestpar(fold, train_data_processed, test_data_processed, features)\n",
    "    \n",
    "    # if you want to just test the code, you should use this\n",
    "    #max_hy = h_space[0]\n",
    "    #print(\"Found maximum hyperparmeter, now work with that\")\n",
    "    \n",
    "    print(\"-------------------------------Testing Begining-------------------------------\")\n",
    "    test_auc,test_acc ,valid_result, clf_res, preds_prob, X_test, Y_test, y_valid_pred, y_test_pred, y_valid_subject, y_test_subject, y_valid_true= bestpar_tuning(fold, \n",
    "                                                                                        train_data_processed, \n",
    "                                                                                        test_data_processed, \n",
    "                                                                                        max_hy, \n",
    "                                                                                        features)\n",
    "    \n",
    "    #print(\"-------------------------------Important Feature-------------------------------\")\n",
    "    import_feat=feature(Num_feat, clf_res, test_data_processed, features)\n",
    "    #import_feat=0\n",
    "    #preds_val_prob = clf.predict_proba(X_valid)\n",
    "\n",
    "    return test_auc,test_acc ,valid_result, clf_res, preds_prob, X_test, Y_test, import_feat, name_test, y_valid_pred, y_test_pred, y_valid_subject, y_test_subject, y_valid_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"해당 버전 추가 코드\"\"\"\n",
    "def save_prob_with_true(model):\n",
    "    modeltype= \"\" \n",
    "    combined_model=pd.DataFrame({f\"subjectkey\": model.y_test_subject[0], f\"Y_{modeltype}\":model.Y_test, f\"preds_prob_{modeltype}\" :model.preds_prob[:,1]} )\n",
    "    combined_model.to_csv(f\"combined_forROC_{modeltype}_.csv\")\n",
    "    #mdoel.import_feat_every.to_csv(f\"{modeltype}_features.csv\")\n",
    "\n",
    "    return combined_model\n",
    "def save_prob_with_true_valid(model):\n",
    "    modeltype= \"\" \n",
    "    \n",
    "    combined_model=pd.DataFrame({f\"subjectkey\": list(itertools.chain(*model.y_valid_subject)), f\"Y_{modeltype}\":list(itertools.chain(*model.y_valid_true)), f\"preds_prob_{modeltype}\" :list(itertools.chain(*model.y_valid_pred) )})\n",
    "    combined_model.to_csv(f\"combined_forROC_{modeltype}_.csv\")\n",
    "    #model.import_feat_every.to_csv(f\"{modeltype}_features.csv\")\n",
    "\n",
    "    return combined_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    def __init__(self, train_data_processed, test_data_processed, Num_FOLDS, Num_feat, features):\n",
    "        test_auc,test_acc ,valid_result, clf_res, preds_prob, X_test, Y_test, import_feat, name_test, y_valid_pred, y_test_pred, y_valid_subject, y_test_subject, y_valid_true = run(train_data_processed,\n",
    "                                                                              test_data_processed,\n",
    "                                                                              Num_FOLDS, \n",
    "                                                                              Num_feat, \n",
    "                                                                              features)\n",
    "    \n",
    "    \n",
    "        self.train_data_processed = train_data_processed\n",
    "        self.test_auc = test_auc\n",
    "        self.test_acc = test_acc\n",
    "        self.valid_result = valid_result\n",
    "        self.clf_res = clf_res \n",
    "        self.preds_prob = preds_prob \n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        self.import_feat =  import_feat\n",
    "        self.name_test = name_test\n",
    "        self.features = features\n",
    "        self.y_valid_pred =y_valid_pred\n",
    "        self.y_test_pred = y_test_pred\n",
    "        self.y_valid_subject= y_valid_subject\n",
    "        self.y_test_subject = y_test_subject\n",
    "        self.y_valid_true = y_valid_true\n",
    "        \"\"\"해당 버전 추가 코드\"\"\"        \n",
    "        test_prob_result = save_prob_with_true(self)\n",
    "        valid_prob_result = save_prob_with_true_valid(self)\n",
    "\n",
    "        \"\"\"해당 버전 추가 코드\"\"\"\n",
    "        self.test_prob_result= test_prob_result\n",
    "        self.valid_prob_result = valid_prob_result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done preprocessing\n"
     ]
    }
   ],
   "source": [
    "train_data_processed, test_data_processed = preprocessing (train_data, test_data, Num_FOLDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "#path to dmri \n",
    "with open (\"./Data/dMRI.pkl\", 'rb') as file:\n",
    "    diffusion_mri = dill.load(file)\n",
    "\n",
    "new_features_D = [col for col in train_data_processed.columns if col in psychosocial + diffusion_mri.import_feat.index.tolist()]\n",
    "\n",
    "new_DMRI = model(train_data_processed, test_data_processed, Num_FOLDS, Num_feat, new_features_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model \n",
    "\n",
    "exp_type = \"Newway_SI\"\n",
    "\n",
    "with open(f'./{exp_type}/new_DMRI.pkl', 'wb') as f:\n",
    "    dill.dump(new_DMRI, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For drawing ROC curve graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocvis(true , prob , label ) :\n",
    "    from sklearn.metrics import roc_curve\n",
    "    if type(true[0]) == str :\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        true = le.fit_transform(true)\n",
    "    else :\n",
    "        pass\n",
    "    fpr, tpr, thresholds = roc_curve(true, prob)\n",
    "    plt.plot(fpr, tpr, marker='.', label = label  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(figsize= (20,10))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "rocvis(new_DMRI.Y_test , new_DMRI.preds_prob[:,1] , f\"new_DMRI:{round(new_DMRI.test_auc*100, 2)}%\")\n",
    "\n",
    "\n",
    "dataset_name=\"dmri\"\n",
    "\n",
    "plt.legend(fontsize = 40)\n",
    "plt.title(dataset_name, fontsize= 50)\n",
    "plt.xlabel(\"FP rate\", fontsize =30)\n",
    "plt.ylabel(\"TP rate\", fontsize =30)\n",
    "plt.xticks(size = 30)\n",
    "plt.yticks(size = 30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{dataset_name}_ROC.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw AUC per epochs and loss per epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_names=[\"Combined\", \"psychosocial\", \"MRI\"]\n",
    "clfs = [clf_all, clf_pheno, clf_mri ]\n",
    "simple_name = \"enbackfMRI\"\n",
    "\n",
    "def error_plot(clf):\n",
    "    plt.plot(clf.history['train_auc'])\n",
    "    plt.plot(clf.history['valid_auc'])\n",
    "\n",
    "for i in range(3):\n",
    "    error_plot(clfs[i])\n",
    "\n",
    "plt.legend([f'train_{feature_names[0]}', f'valid_{feature_names[0]}', \n",
    "           f'train_{feature_names[1]}', f'valid_{feature_names[1]}',\n",
    "           f'train_{feature_names[2]}', f'valid_{feature_names[2]}'])\n",
    "plt.title(f'{simple_name}')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('AUC')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'AUC_per_epochs {simple_name}.png')\n",
    "\n",
    "plt.show()          \n",
    "\n",
    "\n",
    "feature_names=[\"combined\", \"psychosocial\", \"MRI\"]\n",
    "clfs = [clf_all, clf_pheno, clf_mri ]\n",
    "\n",
    "def error_plot(clf):\n",
    "    plt.plot(clf.history['loss'])\n",
    "\n",
    "for i in range(3):\n",
    "    error_plot(clfs[i])\n",
    "\n",
    "plt.legend([f'{feature_names[0]}', \n",
    "           f'{feature_names[1]}',\n",
    "           f'{feature_names[2]}'])\n",
    "plt.title(f'{simple_name}')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'loss_per_epochs {simple_name}.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
