{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data load, set your target and unsused_features\n",
    "\n",
    "train data and valida data would be 75% and 25% of train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch import tensor \n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_data= pd.read_csv('train.mor.csv')\n",
    "test_data= pd.read_csv('test.mor.csv')\n",
    "#df = pd.read_csv('./data/my.nih.norm.csv')\n",
    "#df1 = pd.read_csv('./data/abcd_tbss01.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(0)\n",
    "test_data = test_data.fillna(0)\n",
    "test_data_processed= test_data.reset_index(drop=True)\n",
    "train_data_processed = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target='sex'\n",
    "unused_feat = ['Set', 'subjectkey', 'race.ethnicity', 'abcd_site', 'Unnamed: 0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = [ col for col in train_data_processed.columns if col not in unused_feat + [target]] \n",
    "\n",
    "if \"Set\" not in train_data_processed.columns:\n",
    "    train_data_processed[\"Set\"] = np.random.choice([\"train\", \"valid\"] , p =[.75, .25], size=(train_data_processed.shape[0],))\n",
    "\n",
    "train_indices = train_data_processed[train_data_processed.Set==\"train\"].index\n",
    "valid_indices = train_data_processed[train_data_processed.Set==\"valid\"].index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (5800, 1043)\n",
      "y_train.shape:  (5800,)\n",
      "X_valid.shape:  (2024, 1043)\n",
      "y_valid.shape:  (2024,)\n",
      "X_test.shape:  (1957, 1043)\n",
      "y_test.shape:  (1957,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = train_data_processed[features].values[train_indices]\n",
    "y_train = train_data_processed[target].values[train_indices]\n",
    "X_valid = train_data_processed[features].values[valid_indices]\n",
    "y_valid = train_data_processed[target].values[valid_indices]\n",
    "X_test = test_data_processed[features].values\n",
    "y_test = test_data_processed[target].values\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"y_train.shape: \",y_train.shape)\n",
    "print(\"X_valid.shape: \", X_valid.shape)\n",
    "print(\"y_valid.shape: \",y_valid.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[ 0.15890019  2.34331573  2.5119754  ...  0.68325767  0.78925124\n",
      "   0.68887924]\n",
      " [-0.51212116 -0.03159145 -0.53800352 ... -0.38710003 -0.22538113\n",
      "  -0.11662927]\n",
      " [-0.61728122 -0.66843806 -0.26238929 ... -0.2840919   0.22571588\n",
      "  -0.35856821]\n",
      " ...\n",
      " [-0.10650378  1.13596068 -0.69289416 ...  0.34257862  0.46276225\n",
      "  -0.06168219]\n",
      " [-0.87767756 -0.62200133  0.48473026 ... -1.16414248 -0.64952149\n",
      "  -0.41393306]\n",
      " [ 0.69972336  1.36151053  0.48700807 ...  0.00965159  0.96610002\n",
      "   1.14473944]]\n",
      "y_train:  [2 1 1 ... 1 2 1]\n",
      "X_valid:  [[ 0.09880872  0.67822718  1.19768277 ...  0.05926673  0.30079841\n",
      "   0.54571449]\n",
      " [-0.8876928  -0.24387365 -1.24184481 ... -0.89317866 -1.34036613\n",
      "  -0.93804441]\n",
      " [-1.00787573 -0.58219842 -1.3694018  ...  0.09256084 -0.34782674\n",
      "  -0.05905194]\n",
      " ...\n",
      " [ 0.21899165  0.82417119  2.07691493 ... -0.4489326  -0.61850594\n",
      "  -1.10992749]\n",
      " [-1.48860744 -0.97359373 -1.59718216 ... -0.80068039 -0.81380869\n",
      "  -0.37380318]\n",
      " [-1.02790622  0.17405694  1.67602151 ...  0.86346314  1.01134269\n",
      "   0.46455411]]\n",
      "y_valid:  [1 1 1 ... 2 1 1]\n",
      "X_test:  [[ 1.71126299  1.01655194  2.03819227 ...  2.01882914  2.07433187\n",
      "   1.36821598]\n",
      " [ 0.87499013 -0.01832381  0.36856228 ... -0.26059678  0.18193582\n",
      "   0.45655888]\n",
      " [ 1.14540171  0.14088784 -0.59950421 ... -0.40742471 -0.00823033\n",
      "   0.3659681 ]\n",
      " ...\n",
      " [-0.29679341 -0.64853661 -0.12799888 ... -0.95331409 -1.42163497\n",
      "  -1.28016741]\n",
      " [-0.42699158 -0.33674712  0.00639152 ...  0.16924546  0.14964662\n",
      "  -0.05934405]\n",
      " [ 0.05874775 -1.19914358 -0.56533716 ...  0.50674941  0.31791575\n",
      "  -0.56925536]]\n",
      "y_test:  [1 1 2 ... 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train: \", X_train)\n",
    "print(\"y_train: \",y_train)\n",
    "print(\"X_valid: \", X_valid)\n",
    "print(\"y_valid: \",y_valid)\n",
    "print(\"X_test: \", X_test)\n",
    "print(\"y_test: \",y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa86e54e500404ea0d95b9d3ce7c520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=486.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-82d1538c3155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                            )\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mpreds_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mpreds_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_tabnet/tab_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_valid, y_valid, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mfit_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;31m# leaving it here, may be used for callbacks later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_tabnet/tab_model.py\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(self, train_dataloader, valid_dataloader)\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mDataLoader\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \"\"\"\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mvalid_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_tabnet/tab_model.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                 y_preds.append(torch.nn.Softmax(dim=1)(batch_outs[\"y_preds\"])[:, 1]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_tabnet/tab_model.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, data, targets)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_sparse\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mM_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Augmented\n",
    "import torch\n",
    "import itertools\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "# Store maximum auc\n",
    "max_auc = 0\n",
    "# Store maximum hypterparameter set\n",
    "max_hy = []\n",
    "# define hyperparameter space\n",
    "n_ = [4,8,16]\n",
    "lr_ = [2e-2, 1e-2, 5e-3, 2e-3, 1e-3, 1e-4]\n",
    "w_ = [0.01, 0.001, 0.0001]\n",
    "g_ = [0.95, 0.99, 0.9]\n",
    "ss_ = [10, 20, 30]\n",
    "all_ = [n_, lr_, w_, g_, ss_]\n",
    "h_space = [s for s in itertools.product(*all_)]\n",
    "# Start training\n",
    "\n",
    "\n",
    "for hy in tqdm(h_space):\n",
    "    clf = TabNetClassifier(n_a = hy[0],\n",
    "                           n_d = hy[0],\n",
    "                           optimizer_params = dict(lr=hy[1], weight_decay=hy[2]),\n",
    "                           scheduler_params={\"step_size\":hy[4], \"gamma\":hy[3]},\n",
    "                           scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                           verbose=0\n",
    "                           )\n",
    "    clf.fit(X_train, y_train, X_valid, y_valid, patience=50, batch_size=256, max_epochs=200)\n",
    "    preds_acc = clf.predict(X_test)\n",
    "    preds_prob = clf.predict_proba(X_test)\n",
    "    test_auc = roc_auc_score(y_score=preds_prob[:,1], y_true=y_test)\n",
    "    test_acc = accuracy_score(preds_acc, y_test)\n",
    "    print(\"FINAL TEST SCORE\", test_auc, test_acc)\n",
    "    if test_auc>max_auc:\n",
    "        max_hy = hy\n",
    "        max_auc = test_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4, 0.02, 0.01, 0.95, 10) Test AUC: 0.9348476454293627 \n",
    "(4, 0.02, 0.01, 0.9, 20) Test AUC: 0.935661945330058 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it with best hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target= 'sex'\n",
    "unused_feat = ['fluidcomp', 'Set', 'subjectkey', 'race.ethnicity', 'abcd_site', 'Unnamed: 0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (5775, 1043)\n",
      "y_train.shape:  (5775,)\n",
      "X_valid.shape:  (1870, 1043)\n",
      "y_valid.shape:  (1870,)\n",
      "X_test.shape:  (1923, 1043)\n",
      "y_test.shape:  (1923,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = train_data_processed[features].values[train_indices]\n",
    "y_train = train_data_processed[target].values[train_indices]\n",
    "X_valid = train_data_processed[features].values[valid_indices]\n",
    "y_valid = train_data_processed[target].values[valid_indices]\n",
    "X_test = test_data_processed[features].values\n",
    "y_test = test_data_processed[target].values\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"y_train.shape: \",y_train.shape)\n",
    "print(\"X_valid.shape: \", X_valid.shape)\n",
    "print(\"y_valid.shape: \",y_valid.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c9e3a3880c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpreds_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FINAL TEST SCORE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "hy = (4, 0.02, 0.01, 0.9, 20)\n",
    "clf = TabNetClassifier(n_a = hy[0],\n",
    "                       n_d = hy[0],\n",
    "                       optimizer_params = dict(lr=hy[1], weight_decay=hy[2]),\n",
    "                       scheduler_params={\"step_size\":hy[4], \"gamma\":hy[3]},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       verbose=0\n",
    "                           )\n",
    "clf.fit(X_train, y_train, X_valid, y_valid, patience=50, batch_size=256, max_epochs=200)\n",
    "preds_acc = clf.predict(X_test)\n",
    "preds_prob = clf.predict_proba(X_test)\n",
    "test_auc = roc_auc_score(y_score=preds_prob[:,1], y_true=y_test)\n",
    "test_acc = accuracy_score(preds_acc, y_test)\n",
    "print(\"FINAL TEST SCORE\", test_auc, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def feature(num):\n",
    "    importance =clf.feature_importances_\n",
    "    plt.plot(importance)\n",
    "\n",
    "    labels_importance=importance.argsort()[::-1]\n",
    "\n",
    "    importance_sort = np.sort(importance)[::-1]\n",
    "\n",
    "    feat_name_sort=test_data_processed[features].columns[labels_importance]\n",
    "    important_features = pd.DataFrame() \n",
    "\n",
    "\n",
    "    for i in range (num):\n",
    "        feature = pd.DataFrame([[feat_name_sort[i],importance_sort[i]]], columns = ['feature name', 'ratio'])\n",
    "        important_features=pd.concat([important_features,feature])\n",
    "\n",
    "    print(important_features.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance =clf.feature_importances_\n",
    "plt.plot(importance)\n",
    "\n",
    "labels_importance=importance.argsort()[::-1]\n",
    "\n",
    "importance_sort = np.sort(importance)[::-1]\n",
    "\n",
    "feat_name_sort=test_data_processed[features].columns[labels_importance]\n",
    "important_features = pd.DataFrame() \n",
    "\n",
    "\n",
    "for i in range (5):\n",
    "    feature = pd.DataFrame([[feat_name_sort[i],importance_sort[i]]], columns = ['feature name', 'ratio'])\n",
    "    important_features=pd.concat([important_features,feature])\n",
    "\n",
    "important_features.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ./sexclassification_tabnet_model_mor_1.zip\n",
      "saved_filepath:  ./sexclassification_tabnet_model_mor_1.zip\n"
     ]
    }
   ],
   "source": [
    "saving_path_name = \"./sexclassification_tabnet_model_mor_1\"\n",
    "saved_filepath = clf.save_model(saving_path_name)\n",
    "\n",
    "print(\"saved_filepath: \", saved_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "loaded_clf = TabNetRegressor()\n",
    "loaded_clf.load_model(saved_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_mor=pd.read_csv ('mor_train_with_NIH.csv')\n",
    "test_mor =pd.read_csv ('mor_test_with_NIH.csv')\n",
    "train_NIH =pd.read_csv ('train_with_NIH.csv')\n",
    "test_NIH = pd.read_csv ('test_with_NIH.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_mor=train_mor.assign(fluidcomp=train_NIH['nihtbx_fluidcomp_uncorrected'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_mor=test_mor.assign(fluidcomp=test_NIH['nihtbx_fluidcomp_uncorrected'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subjectkey</th>\n",
       "      <th>sex</th>\n",
       "      <th>race.ethnicity</th>\n",
       "      <th>abcd_site</th>\n",
       "      <th>lh_bankssts_area._.1</th>\n",
       "      <th>lh_caudalanteriorcingulate_area._.1</th>\n",
       "      <th>lh_caudalmiddlefrontal_area._.1</th>\n",
       "      <th>lh_cuneus_area._.1</th>\n",
       "      <th>lh_entorhinal_area._.1</th>\n",
       "      <th>...</th>\n",
       "      <th>wm.rh.transversetemporal._.18</th>\n",
       "      <th>wm.rh.insula._.18</th>\n",
       "      <th>Left.UnsegmentedWhiteMatter._.18</th>\n",
       "      <th>Right.UnsegmentedWhiteMatter._.18</th>\n",
       "      <th>lhCerebralWhiteMatterVol._.18</th>\n",
       "      <th>rhCerebralWhiteMatterVol._.18</th>\n",
       "      <th>CerebralWhiteMatterVol._.18</th>\n",
       "      <th>MaskVol._.18</th>\n",
       "      <th>EstimatedTotalIntraCranialVol._.18</th>\n",
       "      <th>fluidcomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NDAR_INV007W6H7B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1.711263</td>\n",
       "      <td>1.016552</td>\n",
       "      <td>2.038192</td>\n",
       "      <td>0.204396</td>\n",
       "      <td>1.060413</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523832</td>\n",
       "      <td>0.516604</td>\n",
       "      <td>1.493272</td>\n",
       "      <td>1.668963</td>\n",
       "      <td>2.052498</td>\n",
       "      <td>1.981025</td>\n",
       "      <td>2.018829</td>\n",
       "      <td>2.074332</td>\n",
       "      <td>1.368216</td>\n",
       "      <td>0.859540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NDAR_INV00LH735Y</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.874990</td>\n",
       "      <td>-0.018324</td>\n",
       "      <td>0.368562</td>\n",
       "      <td>-0.770356</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692763</td>\n",
       "      <td>-1.209858</td>\n",
       "      <td>-0.107813</td>\n",
       "      <td>-0.292801</td>\n",
       "      <td>-0.245770</td>\n",
       "      <td>-0.274859</td>\n",
       "      <td>-0.260597</td>\n",
       "      <td>0.181936</td>\n",
       "      <td>0.456559</td>\n",
       "      <td>-1.447688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>NDAR_INV00X2TBWJ</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1.145402</td>\n",
       "      <td>0.140888</td>\n",
       "      <td>-0.599504</td>\n",
       "      <td>-1.486840</td>\n",
       "      <td>1.089027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.803677</td>\n",
       "      <td>-0.620718</td>\n",
       "      <td>-0.772871</td>\n",
       "      <td>-0.895455</td>\n",
       "      <td>-0.356828</td>\n",
       "      <td>-0.457092</td>\n",
       "      <td>-0.407425</td>\n",
       "      <td>-0.008230</td>\n",
       "      <td>0.365968</td>\n",
       "      <td>-0.197940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>NDAR_INV01AJ15N9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.078778</td>\n",
       "      <td>-0.482691</td>\n",
       "      <td>0.382229</td>\n",
       "      <td>1.312447</td>\n",
       "      <td>1.680372</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.153354</td>\n",
       "      <td>-1.333109</td>\n",
       "      <td>1.398845</td>\n",
       "      <td>1.132769</td>\n",
       "      <td>1.303689</td>\n",
       "      <td>1.250960</td>\n",
       "      <td>1.278631</td>\n",
       "      <td>1.315186</td>\n",
       "      <td>1.157997</td>\n",
       "      <td>-0.390209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>NDAR_INV01ELX9L6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.022899</td>\n",
       "      <td>-0.668438</td>\n",
       "      <td>0.368562</td>\n",
       "      <td>-0.316305</td>\n",
       "      <td>-1.400345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354574</td>\n",
       "      <td>-1.473899</td>\n",
       "      <td>-1.399160</td>\n",
       "      <td>-1.540223</td>\n",
       "      <td>-1.198914</td>\n",
       "      <td>-1.276079</td>\n",
       "      <td>-1.238815</td>\n",
       "      <td>-1.427905</td>\n",
       "      <td>-1.560898</td>\n",
       "      <td>-0.967016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>9755</td>\n",
       "      <td>NDAR_INVZX24TGXN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.191633</td>\n",
       "      <td>0.107719</td>\n",
       "      <td>0.250117</td>\n",
       "      <td>0.133581</td>\n",
       "      <td>1.365623</td>\n",
       "      <td>...</td>\n",
       "      <td>1.356191</td>\n",
       "      <td>1.675921</td>\n",
       "      <td>0.209144</td>\n",
       "      <td>0.040799</td>\n",
       "      <td>0.937163</td>\n",
       "      <td>0.867282</td>\n",
       "      <td>0.903132</td>\n",
       "      <td>1.330666</td>\n",
       "      <td>1.334954</td>\n",
       "      <td>0.571136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>9756</td>\n",
       "      <td>NDAR_INVZXC2YRV3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.480912</td>\n",
       "      <td>0.200592</td>\n",
       "      <td>0.876512</td>\n",
       "      <td>-0.932814</td>\n",
       "      <td>-0.713622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015423</td>\n",
       "      <td>0.158228</td>\n",
       "      <td>-0.332553</td>\n",
       "      <td>-0.645636</td>\n",
       "      <td>0.324504</td>\n",
       "      <td>0.169126</td>\n",
       "      <td>0.247007</td>\n",
       "      <td>0.438227</td>\n",
       "      <td>0.336904</td>\n",
       "      <td>-0.005671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>9766</td>\n",
       "      <td>NDAR_INVZZ1MNPK5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.296793</td>\n",
       "      <td>-0.648537</td>\n",
       "      <td>-0.127999</td>\n",
       "      <td>-0.832840</td>\n",
       "      <td>-0.894841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.697843</td>\n",
       "      <td>-1.031239</td>\n",
       "      <td>-0.178276</td>\n",
       "      <td>-0.082675</td>\n",
       "      <td>-0.955257</td>\n",
       "      <td>-0.949396</td>\n",
       "      <td>-0.953314</td>\n",
       "      <td>-1.421635</td>\n",
       "      <td>-1.280167</td>\n",
       "      <td>2.013153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>9771</td>\n",
       "      <td>NDAR_INVZZ81LEEV</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.426992</td>\n",
       "      <td>-0.336747</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>1.987275</td>\n",
       "      <td>-1.142824</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.000029</td>\n",
       "      <td>1.074646</td>\n",
       "      <td>-0.002386</td>\n",
       "      <td>-0.148565</td>\n",
       "      <td>0.181019</td>\n",
       "      <td>0.157140</td>\n",
       "      <td>0.169245</td>\n",
       "      <td>0.149647</td>\n",
       "      <td>-0.059344</td>\n",
       "      <td>-0.582478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>9774</td>\n",
       "      <td>NDAR_INVZZL0VA2F</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.058748</td>\n",
       "      <td>-1.199144</td>\n",
       "      <td>-0.565337</td>\n",
       "      <td>1.520727</td>\n",
       "      <td>-0.484714</td>\n",
       "      <td>...</td>\n",
       "      <td>1.478959</td>\n",
       "      <td>0.478680</td>\n",
       "      <td>0.510991</td>\n",
       "      <td>0.385614</td>\n",
       "      <td>0.528357</td>\n",
       "      <td>0.484126</td>\n",
       "      <td>0.506749</td>\n",
       "      <td>0.317916</td>\n",
       "      <td>-0.569255</td>\n",
       "      <td>-1.063150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1923 rows Ã— 1049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        subjectkey  sex  race.ethnicity  abcd_site  \\\n",
       "0              1  NDAR_INV007W6H7B    1               1         22   \n",
       "1              6  NDAR_INV00LH735Y    1               3          3   \n",
       "2             12  NDAR_INV00X2TBWJ    2               3         14   \n",
       "3             18  NDAR_INV01AJ15N9    1               1         16   \n",
       "4             20  NDAR_INV01ELX9L6    2               2          4   \n",
       "...          ...               ...  ...             ...        ...   \n",
       "1918        9755  NDAR_INVZX24TGXN    1               1          9   \n",
       "1919        9756  NDAR_INVZXC2YRV3    1               1         10   \n",
       "1920        9766  NDAR_INVZZ1MNPK5    2               5          8   \n",
       "1921        9771  NDAR_INVZZ81LEEV    1               2         11   \n",
       "1922        9774  NDAR_INVZZL0VA2F    1               2         22   \n",
       "\n",
       "      lh_bankssts_area._.1  lh_caudalanteriorcingulate_area._.1  \\\n",
       "0                 1.711263                             1.016552   \n",
       "1                 0.874990                            -0.018324   \n",
       "2                 1.145402                             0.140888   \n",
       "3                 0.078778                            -0.482691   \n",
       "4                -1.022899                            -0.668438   \n",
       "...                    ...                                  ...   \n",
       "1918             -0.191633                             0.107719   \n",
       "1919              1.480912                             0.200592   \n",
       "1920             -0.296793                            -0.648537   \n",
       "1921             -0.426992                            -0.336747   \n",
       "1922              0.058748                            -1.199144   \n",
       "\n",
       "      lh_caudalmiddlefrontal_area._.1  lh_cuneus_area._.1  \\\n",
       "0                            2.038192            0.204396   \n",
       "1                            0.368562           -0.770356   \n",
       "2                           -0.599504           -1.486840   \n",
       "3                            0.382229            1.312447   \n",
       "4                            0.368562           -0.316305   \n",
       "...                               ...                 ...   \n",
       "1918                         0.250117            0.133581   \n",
       "1919                         0.876512           -0.932814   \n",
       "1920                        -0.127999           -0.832840   \n",
       "1921                         0.006392            1.987275   \n",
       "1922                        -0.565337            1.520727   \n",
       "\n",
       "      lh_entorhinal_area._.1  ...  wm.rh.transversetemporal._.18  \\\n",
       "0                   1.060413  ...                       1.523832   \n",
       "1                   0.001715  ...                      -0.692763   \n",
       "2                   1.089027  ...                      -0.803677   \n",
       "3                   1.680372  ...                      -1.153354   \n",
       "4                  -1.400345  ...                       0.354574   \n",
       "...                      ...  ...                            ...   \n",
       "1918                1.365623  ...                       1.356191   \n",
       "1919               -0.713622  ...                      -0.015423   \n",
       "1920               -0.894841  ...                      -0.697843   \n",
       "1921               -1.142824  ...                      -2.000029   \n",
       "1922               -0.484714  ...                       1.478959   \n",
       "\n",
       "      wm.rh.insula._.18  Left.UnsegmentedWhiteMatter._.18  \\\n",
       "0              0.516604                          1.493272   \n",
       "1             -1.209858                         -0.107813   \n",
       "2             -0.620718                         -0.772871   \n",
       "3             -1.333109                          1.398845   \n",
       "4             -1.473899                         -1.399160   \n",
       "...                 ...                               ...   \n",
       "1918           1.675921                          0.209144   \n",
       "1919           0.158228                         -0.332553   \n",
       "1920          -1.031239                         -0.178276   \n",
       "1921           1.074646                         -0.002386   \n",
       "1922           0.478680                          0.510991   \n",
       "\n",
       "      Right.UnsegmentedWhiteMatter._.18  lhCerebralWhiteMatterVol._.18  \\\n",
       "0                              1.668963                       2.052498   \n",
       "1                             -0.292801                      -0.245770   \n",
       "2                             -0.895455                      -0.356828   \n",
       "3                              1.132769                       1.303689   \n",
       "4                             -1.540223                      -1.198914   \n",
       "...                                 ...                            ...   \n",
       "1918                           0.040799                       0.937163   \n",
       "1919                          -0.645636                       0.324504   \n",
       "1920                          -0.082675                      -0.955257   \n",
       "1921                          -0.148565                       0.181019   \n",
       "1922                           0.385614                       0.528357   \n",
       "\n",
       "      rhCerebralWhiteMatterVol._.18  CerebralWhiteMatterVol._.18  \\\n",
       "0                          1.981025                     2.018829   \n",
       "1                         -0.274859                    -0.260597   \n",
       "2                         -0.457092                    -0.407425   \n",
       "3                          1.250960                     1.278631   \n",
       "4                         -1.276079                    -1.238815   \n",
       "...                             ...                          ...   \n",
       "1918                       0.867282                     0.903132   \n",
       "1919                       0.169126                     0.247007   \n",
       "1920                      -0.949396                    -0.953314   \n",
       "1921                       0.157140                     0.169245   \n",
       "1922                       0.484126                     0.506749   \n",
       "\n",
       "      MaskVol._.18  EstimatedTotalIntraCranialVol._.18  fluidcomp  \n",
       "0         2.074332                            1.368216   0.859540  \n",
       "1         0.181936                            0.456559  -1.447688  \n",
       "2        -0.008230                            0.365968  -0.197940  \n",
       "3         1.315186                            1.157997  -0.390209  \n",
       "4        -1.427905                           -1.560898  -0.967016  \n",
       "...            ...                                 ...        ...  \n",
       "1918      1.330666                            1.334954   0.571136  \n",
       "1919      0.438227                            0.336904  -0.005671  \n",
       "1920     -1.421635                           -1.280167   2.013153  \n",
       "1921      0.149647                           -0.059344  -0.582478  \n",
       "1922      0.317916                           -0.569255  -1.063150  \n",
       "\n",
       "[1923 rows x 1049 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = train_mor.fillna(0)\n",
    "test_data = test_mor.fillna(0)\n",
    "test_data_processed= test_data.reset_index(drop=True)\n",
    "train_data_processed = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target= 'fluidcomp'\n",
    "unused_feat = ['sex', 'Set', 'subjectkey', 'race.ethnicity', 'abcd_site', 'Unnamed: 0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = [ col for col in train_data_processed.columns if col not in unused_feat + [target]] \n",
    "\n",
    "if \"Set\" not in train_data_processed.columns:\n",
    "    train_data_processed[\"Set\"] = np.random.choice([\"train\", \"valid\"] , p =[.75, .25], size=(train_data_processed.shape[0],))\n",
    "\n",
    "train_indices = train_data_processed[train_data_processed.Set==\"train\"].index\n",
    "valid_indices = train_data_processed[train_data_processed.Set==\"valid\"].index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (5775, 1043)\n",
      "y_train.shape:  (5775, 1)\n",
      "X_valid.shape:  (1870, 1043)\n",
      "y_valid.shape:  (1870, 1)\n",
      "X_test.shape:  (1923, 1043)\n",
      "y_test.shape:  (1923, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = train_data_processed[features].values[train_indices]\n",
    "y_train = train_data_processed[target].values[train_indices].reshape(-1, 1)\n",
    "X_valid = train_data_processed[features].values[valid_indices]\n",
    "y_valid = train_data_processed[target].values[valid_indices].reshape(-1, 1)\n",
    "X_test = test_data_processed[features].values\n",
    "y_test = test_data_processed[target].values.reshape(-1, 1)\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"y_train.shape: \",y_train.shape)\n",
    "print(\"X_valid.shape: \", X_valid.shape)\n",
    "print(\"y_valid.shape: \",y_valid.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VALID SCORE FOR  : 0.9386643786643787\n",
      "FINAL TEST SCORE FOR : 0.17212688507540302\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "hy = (4, 0.02, 0.01, 0.9, 20)\n",
    "clf = TabNetClassifier(n_a = hy[0],\n",
    "                       n_d = hy[0],\n",
    "                       optimizer_params = dict(lr=hy[1], weight_decay=hy[2]),\n",
    "                       scheduler_params={\"step_size\":hy[4], \"gamma\":hy[3]},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       verbose=0\n",
    "                           )\n",
    "\"\"\"\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "loaded_clf.fit(X_train, y_train, X_valid, y_valid, patience=50, batch_size=256, max_epochs=200)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "\n",
    "test_score = mean_squared_error(y_pred=preds, y_true=y_true)\n",
    "\n",
    "print(f\"BEST VALID SCORE FOR  : {-clf.best_cost}\")\n",
    "print(f\"FINAL TEST SCORE FOR : {test_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "Will train until validation stopping metric hasn't improved in 50 rounds.\n",
      "---------------------------------------\n",
      "| EPOCH |  train  |   valid  | total time (s)\n",
      "| 1     | -1.00279 |  -0.41659 |   1.3       \n",
      "| 2     | -0.26362 |  -0.28629 |   2.6       \n",
      "| 3     | -0.21511 |  -0.24761 |   3.9       \n",
      "| 4     | -0.19791 |  -0.21979 |   5.2       \n",
      "| 5     | -0.19947 |  -0.21389 |   6.5       \n",
      "| 6     | -0.19349 |  -0.20340 |   7.9       \n",
      "| 7     | -0.19838 |  -0.20587 |   9.1       \n",
      "| 8     | -0.19181 |  -0.20586 |   10.5      \n",
      "| 9     | -0.19287 |  -0.20167 |   11.8      \n",
      "| 10    | -0.18865 |  -0.20289 |   13.1      \n",
      "| 11    | -0.18662 |  -0.19664 |   14.5      \n",
      "| 12    | -0.18520 |  -0.19847 |   15.8      \n",
      "| 13    | -0.18482 |  -0.19703 |   17.1      \n",
      "| 14    | -0.18497 |  -0.21056 |   18.5      \n",
      "| 15    | -0.19004 |  -0.19199 |   19.8      \n",
      "| 16    | -0.18181 |  -0.20457 |   21.1      \n",
      "| 17    | -0.18301 |  -0.19199 |   22.4      \n",
      "| 18    | -0.17833 |  -0.19234 |   23.7      \n",
      "| 19    | -0.17447 |  -0.18537 |   25.1      \n",
      "| 20    | -0.17437 |  -0.19465 |   26.4      \n",
      "| 21    | -0.17345 |  -0.18434 |   27.8      \n",
      "| 22    | -0.16916 |  -0.17820 |   29.1      \n",
      "| 23    | -0.16085 |  -0.17786 |   30.5      \n",
      "| 24    | -0.15907 |  -0.16833 |   31.8      \n",
      "| 25    | -0.13807 |  -0.16188 |   33.2      \n",
      "| 26    | -0.13217 |  -0.15138 |   34.6      \n",
      "| 27    | -0.12144 |  -0.14437 |   36.1      \n",
      "| 28    | -0.11303 |  -0.13784 |   37.4      \n",
      "| 29    | -0.10807 |  -0.13835 |   38.8      \n",
      "| 30    | -0.09933 |  -0.13154 |   40.2      \n",
      "| 31    | -0.09409 |  -0.13542 |   41.6      \n",
      "| 32    | -0.09109 |  -0.12703 |   42.9      \n",
      "| 33    | -0.09086 |  -0.13713 |   44.3      \n",
      "| 34    | -0.08054 |  -0.12259 |   45.8      \n",
      "| 35    | -0.07670 |  -0.12727 |   47.1      \n",
      "| 36    | -0.07197 |  -0.12123 |   48.6      \n",
      "| 37    | -0.07270 |  -0.12589 |   49.9      \n",
      "| 38    | -0.08185 |  -0.12622 |   51.3      \n",
      "| 39    | -0.06902 |  -0.13295 |   52.5      \n",
      "| 40    | -0.06596 |  -0.13119 |   53.9      \n",
      "| 41    | -0.05905 |  -0.12680 |   55.2      \n",
      "| 42    | -0.05698 |  -0.12982 |   56.5      \n",
      "| 43    | -0.05379 |  -0.13053 |   57.9      \n",
      "| 44    | -0.05079 |  -0.13576 |   59.1      \n",
      "| 45    | -0.05073 |  -0.13840 |   60.6      \n",
      "| 46    | -0.04425 |  -0.13126 |   61.8      \n",
      "| 47    | -0.03944 |  -0.13410 |   63.2      \n",
      "| 48    | -0.04754 |  -0.13970 |   64.7      \n",
      "| 49    | -0.04100 |  -0.13448 |   66.0      \n",
      "| 50    | -0.03697 |  -0.14382 |   67.4      \n",
      "| 51    | -0.03405 |  -0.14326 |   68.7      \n",
      "| 52    | -0.04072 |  -0.13759 |   70.0      \n",
      "| 53    | -0.04235 |  -0.13723 |   71.3      \n",
      "| 54    | -0.04308 |  -0.13766 |   72.7      \n",
      "| 55    | -0.04070 |  -0.14761 |   74.0      \n",
      "| 56    | -0.03589 |  -0.14191 |   75.3      \n",
      "| 57    | -0.03483 |  -0.14271 |   76.6      \n",
      "| 58    | -0.03084 |  -0.14940 |   78.0      \n",
      "| 59    | -0.02997 |  -0.14930 |   79.3      \n",
      "| 60    | -0.02759 |  -0.17109 |   80.5      \n",
      "| 61    | -0.03006 |  -0.15247 |   81.8      \n",
      "| 62    | -0.02573 |  -0.15961 |   83.1      \n",
      "| 63    | -0.02853 |  -0.15092 |   84.4      \n",
      "| 64    | -0.02399 |  -0.15842 |   85.7      \n",
      "| 65    | -0.02894 |  -0.15328 |   87.0      \n",
      "| 66    | -0.02898 |  -0.15450 |   88.4      \n",
      "| 67    | -0.02829 |  -0.14983 |   89.7      \n",
      "| 68    | -0.02523 |  -0.15485 |   91.0      \n",
      "| 69    | -0.03014 |  -0.14887 |   92.4      \n",
      "| 70    | -0.03050 |  -0.14409 |   93.8      \n",
      "| 71    | -0.02840 |  -0.15389 |   95.2      \n",
      "| 72    | -0.02465 |  -0.15119 |   96.5      \n",
      "| 73    | -0.02749 |  -0.15316 |   98.0      \n",
      "| 74    | -0.02455 |  -0.14987 |   99.2      \n",
      "| 75    | -0.02407 |  -0.15663 |   100.5     \n",
      "| 76    | -0.02161 |  -0.16117 |   101.8     \n",
      "| 77    | -0.01985 |  -0.15973 |   103.1     \n",
      "| 78    | -0.02116 |  -0.14773 |   104.3     \n",
      "| 79    | -0.01902 |  -0.15189 |   105.7     \n",
      "| 80    | -0.01729 |  -0.15155 |   107.0     \n",
      "| 81    | -0.01698 |  -0.14491 |   108.2     \n",
      "| 82    | -0.01814 |  -0.15140 |   109.6     \n",
      "| 83    | -0.01948 |  -0.15405 |   110.9     \n",
      "| 84    | -0.02016 |  -0.14898 |   112.4     \n",
      "| 85    | -0.01994 |  -0.15696 |   113.8     \n",
      "| 86    | -0.01767 |  -0.15827 |   115.1     \n",
      "Early stopping occured at epoch 86\n",
      "Training done in 115.063 seconds.\n",
      "---------------------------------------\n",
      "BEST VALID SCORE FOR  : 0.12122908979654312\n",
      "FINAL TEST SCORE FOR : 0.1204910654216671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "clf = TabNetRegressor()\n",
    "\n",
    "clf.fit(X_train, y_train, X_valid, y_valid, patience=50, batch_size=256, max_epochs=200)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "y_true = y_test\n",
    "\n",
    "test_score = mean_squared_error(y_pred=preds, y_true=y_true)\n",
    "\n",
    "print(f\"BEST VALID SCORE FOR  : {clf.best_cost}\")\n",
    "print(f\"FINAL TEST SCORE FOR : {test_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
